# convert model_df to a spatial object
# poly2nb() from the spdep package works with sp objects, not sf objects
model_df_sp <- as(model_df, "Spatial")
# create standard adjacency matrix using queen contiguity
# queen's contiguity considers any shared boundary or vertex as a neighbor
# 'snap = 200' ensures polygons within 200m are considered contiguous
adj_list <- poly2nb(model_df_sp, queen = TRUE, snap = 200)
# inspect adjacency list
# the list has 6 subgraphs and 4 isolated regions (e.g., 59, 177, 184, 190) with no links
adj_list
# convert the list-based adjacency structure into an igraph object to analyze connected components
graph_adj <- graph_from_adj_list(adj_list, mode = "all")
# identify subgraph components
subgraph_labels <- components(graph_adj)$membership
model_df$subgraph <- as.factor(subgraph_labels)
# find the largest subgraph (mainland korea)
largest_subgraph <- which.max(table(subgraph_labels))
# identify all smaller disconnected subgraphs
disconnected_subgraphs <- unique(subgraph_labels[subgraph_labels != largest_subgraph])
# inspect the disconnected subgraphs
disconnected_subgraphs  # should return a list of subgraph ids
# visualise current subgraph connectivity
ggplot() +
geom_sf(data = model_df, aes(fill = as.factor(subgraph_labels)), color = "black") +
scale_fill_viridis_d(option = "turbo", name = "subgraph") +
ggtitle("current subgraph connectivity in south korea") +
theme_minimal()
# convert centroids to an sf object
centroids <- st_centroid(model_df$geometry)
centroids_sf <- st_as_sf(data.frame(id = 1:length(centroids), geometry = centroids))
# iterate through each disconnected subgraph and connect it to the mainland
for (subgraph in disconnected_subgraphs) {
# find polygons in the current subgraph
subgraph_polygons <- which(subgraph_labels == subgraph)
# find polygons in the mainland
mainland_polygons <- which(subgraph_labels == largest_subgraph)
# find the nearest polygon in the mainland for each polygon in the subgraph
closest_mainland <- st_nearest_feature(centroids_sf[subgraph_polygons, ], centroids_sf[mainland_polygons, ])
# convert to integer indices
closest_mainland <- as.integer(closest_mainland)
# update the adjacency list with new bidirectional connections
for (i in seq_along(subgraph_polygons)) {
island <- subgraph_polygons[i]
mainland <- closest_mainland[i]
adj_list[[island]] <- unique(c(adj_list[[island]], mainland))
adj_list[[mainland]] <- unique(c(adj_list[[mainland]], island))
}
}
# identify any nodes with invalid '0' entries (e.g., 59, 177, 184, 190)
invalid_nodes <- which(sapply(adj_list, function(x) any(x == 0)))
print(invalid_nodes)  # should show problematic nodes
# remove 0s from adjacency list
adj_list <- lapply(adj_list, function(x) x[x != 0])
# verify that invalid entries are removed
nodes_to_check <- c(59, 177, 184, 190)
print(adj_list[nodes_to_check])
# recompute the graph after linking subgraphs
graph_adj <- graph_from_adj_list(adj_list, mode = "all")
subgraph_labels <- components(graph_adj)$membership
model_df$subgraph <- as.factor(subgraph_labels)
# check if any disconnected subgraphs remain
remaining_disconnected <- unique(subgraph_labels[subgraph_labels != largest_subgraph])
if (length(remaining_disconnected) == 0) {
message("all regions are now fully connected.")
} else {
message("some subgraphs are still disconnected: ", paste(remaining_disconnected, collapse = ", "))
}
# visualise the updated subgraph connectivity
ggplot() +
geom_sf(data = model_df, aes(fill = as.factor(subgraph_labels)), color = "black") +
scale_fill_viridis_d(option = "turbo", name = "subgraph") +
ggtitle("updated subgraph connectivity in south korea") +
theme_minimal()
# convert the updated graph to an adjacency matrix
adjacency_matrix <- as_adjacency_matrix(graph_adj, sparse = TRUE)
adjacency_matrix <- Matrix::Matrix(as(adjacency_matrix, "sparseMatrix") > 0, sparse = TRUE)
# inspect adjacency matrix
adjacency_matrix
# extract the components for the icar model using the prep_icar_data function
extract_components <- prep_icar_data(adjacency_matrix)
# the extract_components object contains the following key elements:
# group_size: total number of areal units observed in the shapefile
# node1: indexes of the regions of interest — the focal areas in the adjacency matrix
# node2: corresponding neighbouring regions connected to node1 regions — defines spatial relationships
# n_edges: number of edges in the network — transforms the adjacency matrix into a spatial network of direct connections
# extract key elements
n <- as.numeric(extract_components$group_size)
nod1 <- extract_components$node1
nod2 <- extract_components$node2
n_edges <- as.numeric(extract_components$n_ed)
# exploratory plotting to estimate each predictor's relationship with the target variable
target_var <- "suicide_rate"
predictors <- c("single_person_household_ratio",
"stress_awareness_rate",
"unemployment_rate",
"unmet_medical_needs_rate")
# loop through each predictor and create scatterplots
for (predictor in predictors) {
p <- ggplot(model_df, aes_string(x = predictor, y = target_var)) +
geom_point(alpha = 0.5) +  # scatter points with transparency
geom_smooth(method = "lm", color = "blue", se = TRUE) +  # add regression line
theme_minimal() +
labs(
title = paste("scatterplot of", predictor, "vs", target_var),
x = predictor,
y = target_var
) +
theme_classic() +
theme(plot.title = element_text(hjust = 0.5))  # center the title
print(p)  # display the plot
}
# extract variables for modelling
# y: outcome variable (suicide casualties)
y <- model_df$suicide_count
# x: independent variables as a matrix (drop spatial geometry)
X <- model_df %>%
st_drop_geometry() %>%
dplyr::select(
single_person_household_ratio,
stress_awareness_rate,
unemployment_rate,
unmet_medical_needs_rate
) %>%
as.matrix()
# e: expected number of cases (used as offset in the model)
e <- model_df$expected_num
# extract variables for modelling
# y: outcome variable (suicide casualties)
y <- model_df$suicide_count
# x: independent variables as a matrix (drop spatial geometry)
X <- model_df %>%
st_drop_geometry() %>%
dplyr::select(
single_person_household_ratio,
stress_awareness_rate,
unemployment_rate,
unmet_medical_needs_rate
) %>%
as.matrix()
# e: expected number of cases (used as offset in the model)
e <- model_df$expected_num
# view estimated results for alpha, beta, and sigma
# all rhat values below 1.05 indicate good convergence across chains
options(scipen = 999)  # suppress scientific notation for cleaner output
summary(icar_poisson_fit, pars = c("alpha", "beta", "sigma"), probs = c(0.025, 0.975))$summary
# rhat — all values are ≈ 1, which means the model has converged well across all chains
# effective sample sizes (n_eff) are all quite large, indicating low autocorrelation in the markov chains
# (larger n_eff means more precise estimates)
# fixed effect interpretations:
# single_person_household_ratio and unmet_medical_needs_rate have slightly positive associations with suicide rate
# unemployment_rate has a borderline significant, negative association with suicide rate
# stress_awareness_rate has a small, borderline significant negative effect close to 0
# relative risk estimates:
# single_person_household_ratio (1.01) → 1% increase in risk per unit increase
# stress_awareness_rate (0.99) → 1% decrease in risk per unit increase
# unemployment_rate (0.96) → 4% decrease in risk per unit increase (strongest effect)
# unmet_medical_needs_rate (1.01) → 1% increase in risk per unit increase
# alpha (global baseline):
# alpha of -0.20 (95% cri: -0.45 to 0.07) indicates a small negative baseline risk for suicide rates
# sigma (standard deviation):
# sigma of 0.21 (95% cri: 0.16 to 0.27) reflects the overall spatial variability captured by the icar term
# print full table to avoid some rows from being omitted.
options(max.print = 100000)
# print the results
print(icar_poisson_fit, pars=c("alpha", "beta", "rr_alpha", "rr_beta", "rr_mu", "sigma"), probs=c(0.025, 0.975))
# rapid diagnostics of the rhat values
# extract summary for all key parameters and convert to data frame
diagnostic_checks <- as.data.frame(
summary(icar_poisson_fit,
pars = c("alpha", "beta", "rr_alpha", "rr_beta", "rr_mu", "sigma", "phi", "lp__"),
probs = c(0.025, 0.5, 0.975)
)$summary
)
# create binary variable to flag convergence
diagnostic_checks$valid <- ifelse(diagnostic_checks$Rhat < 1.05, 1, 0)
# tabulate how many parameters passed the rhat threshold - all parameters pass the rhat threshold
table(diagnostic_checks$valid)
# all output parameters have an rhat < 1.05
# it is always good to run 10000, 15000 or more iterations,
# as shorter runs often yield low effective sample sizes after warm-up samples are discarded
# this may lead to convergence issues and rhats above 1.05
# extract key posterior results for the generated quantities (relative risk estimates)
relative_risk_results <- as.data.frame(
summary(icar_poisson_fit, pars = "rr_mu", probs = c(0.025, 0.975))$summary
)
# clean up row names for clarity
row.names(relative_risk_results) <- 1:nrow(relative_risk_results)
# check for validity of rhat values
relative_risk_results$valid <- ifelse(relative_risk_results$Rhat < 1.05, 1, 0)
# rearrange and select relevant columns
relative_risk_results <- relative_risk_results[, c("mean", "2.5%", "97.5%", "Rhat", "valid")]
# rename the columns
colnames(relative_risk_results) <- c("rr", "rrlower", "rrupper", "rhat", "valid")
# inspect the clean table
head(relative_risk_results)
# insert relative risk estimates into model_df
model_df$rr <- relative_risk_results$rr
model_df$rrlower <- relative_risk_results$rrlower
model_df$rrupper <- relative_risk_results$rrupper
# these relative risk values allow us to map suicide risk across South Korean municipalities
# we also want a supporting map showing where risks are significantly above or below the baseline
# to do this, we create a new column in model_df called 'significance'
# significance codes:
#  1  = significant increase in risk (rrlower > 1)
# -1  = significant decrease in risk (rrupper < 1)
#  0  = not significant (credible interval overlaps 1)
model_df$significance <- NA
model_df$significance[model_df$rrlower > 1 & model_df$rrupper > 1] <- 1    # significant increase
model_df$significance[model_df$rrlower < 1 & model_df$rrupper < 1] <- -1   # significant decrease
model_df$significance[is.na(model_df$significance)] <- 0                   # not significant
# map design for relative risk — this helps understand how risks are distributed spatially
summary(model_df$rr)
hist(model_df$rr)
# refined risk categories for clearer interpretation and visual separation
risk_category_list <- c(
"≤0.75",
"0.76 to 0.85",
"0.86 to 0.95",
"0.96 to 1.00",
"1.01 to 1.05",
"1.06 to 1.10",
"1.11 to 1.18",
"1.19 to 1.25",
"1.26 to 1.50",
">1.50"
)
# define a custom color palette for these categories
RRPalette <- c(
"#4575B4",  # dark blue
"#5EA9D4",  # medium blue
"#74ADD1",  # light blue
"#ABD9E9",  # pale blue
"#E0F3F8",  # very light blue
"#FFFFBF",  # yellow-white
"#FEE08B",  # light orange
"#FDAE61",  # orange
"#F46D43",  # dark orange-red
"#A50026"   # deep red
)
# assign numeric bins for relative risk values
model_df$relative_risk_cat <- NA
model_df$relative_risk_cat[model_df$rr <= 0.75] <- -4
model_df$relative_risk_cat[model_df$rr > 0.75 & model_df$rr <= 0.85] <- -3
model_df$relative_risk_cat[model_df$rr > 0.85 & model_df$rr <= 0.95] <- -2
model_df$relative_risk_cat[model_df$rr > 0.95 & model_df$rr <= 1.00] <- -1
model_df$relative_risk_cat[model_df$rr > 1.00 & model_df$rr <= 1.05] <- 0
model_df$relative_risk_cat[model_df$rr > 1.05 & model_df$rr <= 1.10] <- 1
model_df$relative_risk_cat[model_df$rr > 1.10 & model_df$rr <= 1.18] <- 2
model_df$relative_risk_cat[model_df$rr > 1.18 & model_df$rr <= 1.25] <- 3
model_df$relative_risk_cat[model_df$rr > 1.25 & model_df$rr <= 1.50] <- 4
model_df$relative_risk_cat[model_df$rr > 1.50] <- 5
# convert to factor and assign labels for plotting
model_df$relative_risk_cat <- factor(
model_df$relative_risk_cat,
levels = -4:5,
labels = risk_category_list
)
# check distribution of categories
table(model_df$relative_risk_cat)
# create relative risk map
rr_map <- tm_shape(model_df) +
tm_polygons("relative_risk_cat",
style = "cat",
title = "relative risk",
palette = RRPalette,
labels = risk_category_list,
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect map
rr_map
# save relative risk map to PNG
tmap_save(tm = rr_map,
filename = here::here("assets", "relative_risk", "relative_risk_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# create significance map
sg_map <- tm_shape(model_df) +
tm_polygons("significance",
style = "cat",
title = "significance categories",
palette = c("#33a6fe", "white", "#fe0000"),
labels = c("significantly low", "not significant", "significantly high"),
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect map
sg_map
# save significance map to PNG
tmap_save(tm = sg_map,
filename = here::here("assets", "significance_categories", "significance_categories_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# create the labels for the probabilities
prob_cat_list <- c("<0.01", "0.01-0.09", "0.10-0.19", "0.20-0.29", "0.30-0.39", "0.40-0.49","0.50-0.59", "0.60-0.69", "0.70-0.79", "0.80-0.89", "0.90-0.99", "1.00")
# categorising the probabilities in bands of 10s
model_df$prob_cat <- NA
model_df$prob_cat[model_df$exceedance_probability>=0 & model_df$exceedance_probability< 0.01] <- 1
model_df$prob_cat[model_df$exceedance_probability>=0.01 & model_df$exceedance_probability< 0.10] <- 2
model_df$prob_cat[model_df$exceedance_probability>=0.10 & model_df$exceedance_probability< 0.20] <- 3
model_df$prob_cat[model_df$exceedance_probability>=0.20 & model_df$exceedance_probability< 0.30] <- 4
model_df$prob_cat[model_df$exceedance_probability>=0.30 & model_df$exceedance_probability< 0.40] <- 5
model_df$prob_cat[model_df$exceedance_probability>=0.40 & model_df$exceedance_probability< 0.50] <- 6
model_df$prob_cat[model_df$exceedance_probability>=0.50 & model_df$exceedance_probability< 0.60] <- 7
model_df$prob_cat[model_df$exceedance_probability>=0.60 & model_df$exceedance_probability< 0.70] <- 8
model_df$prob_cat[model_df$exceedance_probability>=0.70 & model_df$exceedance_probability< 0.80] <- 9
model_df$prob_cat[model_df$exceedance_probability>=0.80 & model_df$exceedance_probability< 0.90] <- 10
model_df$prob_cat[model_df$exceedance_probability>=0.90 & model_df$exceedance_probability< 1.00] <- 11
model_df$prob_cat[model_df$exceedance_probability == 1.00] <- 12
# check to see if legend scheme is balanced
table(model_df$prob_cat)
# create relative risk map
rr_map <- tm_shape(model_df) +
tm_polygons("relative_risk_cat",
style = "cat",
title = "Relative Risk",
palette = RRPalette,
labels = risk_category_list,
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect map
rr_map
# save relative risk map to PNG
tmap_save(tm = rr_map,
filename = here::here("assets", "relative_risk", "relative_risk_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# create significance map
sg_map <- tm_shape(model_df) +
tm_polygons("significance",
style = "cat",
title = "Significance Categories",
palette = c("#33a6fe", "white", "#fe0000"),
labels = c("Significantly low", "Not significant", "Significantly high"),
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect map
sg_map
# save significance map to PNG
tmap_save(tm = sg_map,
filename = here::here("assets", "significance_categories", "significance_categories_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# exceedance probabilities allow us to quantify uncertainty around spatial risk estimates
# we define a threshold (e.g., rr > 1) and compute the probability that each area exceeds it
# this helps visualise where elevated risk is not only high, but statistically probable
# for this extraction, we use functions from tidybayes and tidyverse: spread_draws(), group_by(), summarise(), pull()
threshold <- function(x) { mean(x > 1.00) }
# extract exceedance probabilities from the model
exceedance_probability <- icar_poisson_fit %>%
spread_draws(rr_mu[i]) %>%
group_by(i) %>%
summarise(rr_mu = threshold(rr_mu)) %>%
pull(rr_mu)
# insert exceedance probabilities into model_df
model_df$exceedance_probability <- exceedance_probability
# categorise using cut() for efficiency
model_df$prob_cat <- cut(
model_df$exceedance_probability,
breaks = c(-Inf, 0.01, seq(0.1, 1, by = 0.1)),
labels = 1:12,
right = FALSE
)
# create the labels for the exceedance probability categories
prob_cat_list <- c(
"<0.01", "0.01-0.09", "0.10-0.19", "0.20-0.29", "0.30-0.39", "0.40-0.49",
"0.50-0.59", "0.60-0.69", "0.70-0.79", "0.80-0.89", "0.90-0.99", "1.00"
)
# categorise the exceedance probabilities into 12 bands
model_df$prob_cat <- NA
model_df$prob_cat[model_df$exceedance_probability >= 0 & model_df$exceedance_probability < 0.01] <- 1
model_df$prob_cat[model_df$exceedance_probability >= 0.01 & model_df$exceedance_probability < 0.10] <- 2
model_df$prob_cat[model_df$exceedance_probability >= 0.10 & model_df$exceedance_probability < 0.20] <- 3
model_df$prob_cat[model_df$exceedance_probability >= 0.20 & model_df$exceedance_probability < 0.30] <- 4
model_df$prob_cat[model_df$exceedance_probability >= 0.30 & model_df$exceedance_probability < 0.40] <- 5
model_df$prob_cat[model_df$exceedance_probability >= 0.40 & model_df$exceedance_probability < 0.50] <- 6
model_df$prob_cat[model_df$exceedance_probability >= 0.50 & model_df$exceedance_probability < 0.60] <- 7
model_df$prob_cat[model_df$exceedance_probability >= 0.60 & model_df$exceedance_probability < 0.70] <- 8
model_df$prob_cat[model_df$exceedance_probability >= 0.70 & model_df$exceedance_probability < 0.80] <- 9
model_df$prob_cat[model_df$exceedance_probability >= 0.80 & model_df$exceedance_probability < 0.90] <- 10
model_df$prob_cat[model_df$exceedance_probability >= 0.90 & model_df$exceedance_probability < 1.00] <- 11
model_df$prob_cat[model_df$exceedance_probability == 1.00] <- 12
# check distribution of exceedance probability categories
table(model_df$prob_cat)
# define a lighter custom palette for exceedance probability categories
light_gnbu <- c(
"#f7fcf0", "#e0f3db", "#ccebc5", "#a8ddb5", "#7bccc4",
"#4eb3d3", "#2b8cbe", "#0868ac", "#084081"
)
# create the exceedance probability map
ep_map <- tm_shape(model_df) +
tm_polygons("prob_cat",
style = "cat",
title = "probability",
palette = light_gnbu,
labels = prob_cat_list,
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect the map
ep_map
# save the map as a high-resolution PNG
tmap_save(tm = ep_map,
filename = here::here("assets", "exceedance_probabilities", "exceedance_probabilities_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# interpretation:
# the map displays exceedance probabilities for suicide risk across south korea,
# visualising the likelihood that each municipality exceeds a relative risk threshold of 1.00
# values range from <0.01 (very low exceedance probability) to 1.00 (very high),
# illustrating the spatial heterogeneity in suicide risk
# seoul and surrounding metropolitan areas show low exceedance probabilities (0.01–0.39),
# suggesting lower relative suicide risk in capital regions compared to the national average
# rural and peripheral regions tend to exhibit higher exceedance probabilities (0.50–1.00),
# indicating stronger evidence of elevated suicide risk outside major urban centers
# metropolitan cities in general show lower levels of suicide risk than rural areas
# this pattern provides strong evidence of spatial clustering in suicide risk across the country
# define a lighter custom palette for exceedance probability categories
light_gnbu <- c(
"#f7fcf0", "#e0f3db", "#ccebc5", "#a8ddb5", "#7bccc4",
"#4eb3d3", "#2b8cbe", "#0868ac", "#084081"
)
# create the exceedance probability map
ep_map <- tm_shape(model_df) +
tm_polygons("prob_cat",
style = "cat",
title = "Probability",
palette = light_gnbu,
labels = prob_cat_list,
border.col = "black",
border.alpha = 0.2) +
tm_shape(sk_provinces_2022) +
tm_borders(lwd = 1, col = "black") +
tm_scale_bar(position = c("left", "bottom"), width = 0.1, text.size = 0.4) +
tm_compass(position = c("right", "top"), size = 1, type = "arrow") +
tm_layout(
frame = TRUE,
legend.title.size = 0.9,
legend.text.size = 0.7,
legend.frame = TRUE
)
# inspect the map
ep_map
# save the map as a high-resolution PNG
tmap_save(tm = ep_map,
filename = here::here("assets", "exceedance_probabilities", "exceedance_probabilities_map_2022.png"),
width = 7,
height = 9,
dpi = 300)
# interpretation:
# the map displays exceedance probabilities for suicide risk across south korea,
# visualising the likelihood that each municipality exceeds a relative risk threshold of 1.00
# values range from <0.01 (very low exceedance probability) to 1.00 (very high),
# illustrating the spatial heterogeneity in suicide risk
# seoul and surrounding metropolitan areas show low exceedance probabilities (0.01–0.39),
# suggesting lower relative suicide risk in capital regions compared to the national average
# rural and peripheral regions tend to exhibit higher exceedance probabilities (0.50–1.00),
# indicating stronger evidence of elevated suicide risk outside major urban centers
# metropolitan cities in general show lower levels of suicide risk than rural areas
# this pattern provides strong evidence of spatial clustering in suicide risk across the country
