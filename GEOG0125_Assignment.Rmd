GEOG0125 - Advanced Topics in Social and Geographic Data Science

Bayesian Spatial Risk Modelling of Suicide Casualties Across South Korean Local Authorities

We will use a series of spatial models from a Bayesian framework to estimate the area-specific relative risks (RR) of casualties due to suicide in local authority areas across South Korea. We will then quantify the levels of uncertainty using exceedance probabilities.

Model Used: Spatial Intrinsic Conditional Auto-regressive Model (ICAR)

We will use the ICAR model to predict the area-specific relative risks (RR) for areal units and determine whether the levels of such risks are statistically significant or not through 95% credible intervals (95% CrI).

We will then determine the exceedance probability i.e. the probability that an area has an excess risk of an outcome that exceeds a given risk threshold (RR > 1).

1. Loading Libraries

```{r}
# load required packages for spatial analysis, Bayesian modelling, and data manipulation

# sf provides tools for handling spatial data in R
library(sf)

# tmap is used for visualising spatial data
library(tmap)

# spdep supports spatial dependence modelling (e.g., neighbours and spatial weights)
library(spdep)

# rstan is an interface to Stan for Bayesian statistical modelling
library(rstan)      

# geostan contains functions for preparing spatial adjacency structures for Stan - specifically, we will use shape2mat() and prep_icar_data() to create adjacency matrices as nodes and edges
library(geostan)    

# SpatialEpi provides functions for epidemiological spatial analysis, including expected() to calculate expected counts in disease mapping
library(SpatialEpi)

# tidybayes is used for working with Bayesian posterior distributions, including managing posterior estimates and calculating exceedance probabilities
library(tidybayes)

# tidyverse is used for data wrangling, visualisation, and manipulation
library(tidyverse)

# here manages file paths reliably across different operating systems
library(here)

# readxl reads in xls an xlsx files
library(readxl)

# units enables unit setting for st_area()
library(units)

# ggplot2 enables data visualisation
library(ggplot2)

# loo allows the user to perform model validation and comparison
library(loo)

# MASS gives us access to the glm.nb() function to estimate the dispersion parameter for use in Bayesian model
library(MASS)

library(igraph)

library(RColorBrewer)
```

2. Data Loading and Pre-Processing

2.1. Loading South Korea Municipality-Level (City/County/District) Shapefile

```{r}
# load the South Korean municipalities (City/County/District) dataset based on 2022 boundaries
# options = "ENCODING=CP949" ensures proper encoding for Korean characters
sk_municipalities_2022 <- st_read(here::here("SIG_20221119", "sig.shp"), options = "ENCODING=CP949") %>% 
  # select only the relevant columns
  dplyr::select(SIG_CD, SIG_KOR_NM) %>% 
  # rename columns for better readability
  dplyr::rename(
    code = SIG_CD,
    name = SIG_KOR_NM
  )
```

2.2. Loading Municipalities Mapping Data

```{r}
# read and process municipalities mapping
# the locale setting ensures proper encoding (UTF-8) for Korean characters
# the column types are explicitly set to treat "법정동코드" or code as a character to enable string operations
municipalities_mapping <- read_csv(here::here("mapping", "administrative_area_codes.csv"),
                                   locale = locale(encoding = "UTF-8"),
                                   col_types = cols("법정동코드" = col_character())
                                   ) %>% 
  # translate columns to English
  dplyr::rename(
    code = "법정동코드",
    name = "법정동명",
    status = "폐지여부"
  ) %>% 
  # keep only the rows where the status indicates the area still exists ("존재" means "existing")
  dplyr::filter(status == "존재") %>% 
  # filter only for municipality-level areas (codes ending in "00000")
  # codes ending in anything other than "00000" indicate more granular administrative divisions not relevant for this analysis
  dplyr::filter(str_detect(code, "00000$")) %>% 
  # remove the trailing "00000" from the codes to align with codes in the shapefile
  dplyr::mutate(code = str_remove(code, "00000$")) %>% 
  # retain only relevant columns
  dplyr::select(code, name) %>% 
  # standardise the naming convention for specific special administrative regions:
  # - "전북특별자치도" (Jeonbuk Special Self-Governing Province) → "전라북도" (Jeollabuk-do)
  # - "강원특별자치도" (Gangwon Special Self-Governing Province) → "강원도" (Gangwon-do)
  # - "제주특별자치도" (Jeju Special Self-Governing Province) → "제주도" (Jeju-do)
  dplyr::mutate(name = str_replace(name, "^전북특별자치도", "전라북도"),
         name = str_replace(name, "^강원특별자치도", "강원도"),
         name = str_replace(name, "^제주특별자치도", "제주도")
         )
```

2.3. Merging Municipalities Mapping Data With Shapefile

```{r}
# merge municipality mapping data with the shapefile, based on the shared "code" column
sk_municipalities_mapped <- sk_municipalities_2022 %>% 
  # left join to merge municipality mapping data onto the shapefile data
  dplyr::left_join(municipalities_mapping, by="code") %>% 
  # handle missing municipality names for regions whose names have changed since 2022
  # some codes do not have a direct match in 'municipalities_mapping' (as they had been assigned new codes when their names changed to Special Self-Governing Provinces)
  # so we assign names based on their original names
  dplyr::mutate(name.y = case_when(
    # if the code starts with "42" (Gangwon Province) and the name is missing, use "강원도" + existing name in shapefile
    str_starts(code, "42") & is.na(name.y) ~ paste("강원도", name.x),
    # if the code starts with "45" (Jeollabuk-do) and the name is missing, use "전라북도" + existing name in shapefile
    str_starts(code, "45") & is.na(name.y) ~ paste("전라북도", name.x),
    # if the code starts with "47" (Gyeongsangbuk-do) and the name is missing, use "경상북도" + existing name in shapefile
    str_starts(code, "47") & is.na(name.y) ~ paste("경상북도", name.x),
    # otherwise, keep the assisgned municipality names from the join
    TRUE ~ name.y
  )) %>% 
  # select only relevant columns
  dplyr::select(code, name.y) %>% 
  # rename 'name.y' to 'name'
  dplyr::rename(name = name.y)
```

2.4. Aggregating Districts within Ordinary Cities to Match Target Variable Spatial Granularity

```{r}
# separate the dataset into two parts, with rows 76 onward containing ordinary cities and their districts
# the first 75 rows will remain unchanged, as the target variable will have the data for districts within special & metropolitan cities
sk_municipalities_1 <- sk_municipalities_mapped[1:75, ]
# certain rows from row 76 onward will be aggregated, as the target variable will not have the data for districts within ordinary cities
sk_municipalities_2 <- sk_municipalities_mapped[76:nrow(sk_municipalities_mapped), ]

# group districts into their parent cities
# some ordinary cities consist of multiple districts, which need to be merged at the city level
sk_municipalities_2 <- sk_municipalities_2 %>% 
  # create a 'city' column to assign districts to their respective parent cities
  mutate(city = case_when(
    str_detect(name, "수원시") ~ "경기도 수원시",
    str_detect(name, "성남시") ~ "경기도 성남시",
    str_detect(name, "안양시") ~ "경기도 안양시",
    str_detect(name, "안산시") ~ "경기도 안산시",
    str_detect(name, "고양시") ~ "경기도 고양시",
    str_detect(name, "용인시") ~ "경기도 용인시",
    str_detect(name, "청주시") ~ "충청북도 청주시",
    str_detect(name, "천안시") ~ "충청남도 천안시",
    str_detect(name, "전주시") ~ "전라북도 전주시",
    str_detect(name, "포항시") ~ "경상북도 포항시",
    str_detect(name, "창원시") ~ "경상남도 창원시",
    TRUE ~ name # keep other names unchanged
  ))

# merge districts into their corresponding parent cities
# group by the newly assigned 'city' column and use st_union() to combine the geometries into a single shape per city
sk_municipalities_2 <- sk_municipalities_2 %>% 
  dplyr::group_by(city) %>% 
  dplyr::summarise(geometry = st_union(geometry, .groups = "drop"))

# merge back aggregated data with unchanged municipalities
sk_municipalities_merged <- dplyr::bind_rows(sk_municipalities_1, sk_municipalities_2) %>% 
  # coalesce the newly created 'city' column into the orignal 'name'
  dplyr::mutate(name = coalesce(name, city)) %>% 
  # keep only the 'name' column. We will primarily be working with standardised municipality names for subsequent joins
  dplyr::select(name)

# clean up variables unnecessary for down-stream analysis
remove(sk_municipalities_1)
remove(sk_municipalities_2)
```

2.5. Re-mapping Municipalities to Retrieve Standardised Codes

```{r}
# join back with 'municipalities_mapping' by 'name' to retrieve official codes
sk_municipalities_clean <- sk_municipalities_merged %>%
  # we left join to re-assign proper code names based on the municipality name
  dplyr::left_join(municipalities_mapping, by = "name")%>%
  # keep only the relevant columns
  dplyr::select(code, name) %>%
  # manually address discrepancy in '군위군' (Gunwi County) - the country was officially integrated into Daegu Metropolitan City only in 2023
  dplyr::mutate(code = case_when(
    # we manually assign the code "47720" to Gunwi County - its code as of 2022, prior to administrative integration
    name == "경상북도 군위군" ~ "47720",
    # keep other codes unchanged
    TRUE ~ code
  )) %>% 
  # convert 'code' column to integer type for correct sorting
  dplyr::mutate(code = as.integer(code)) %>% 
  # sort by code in an ascending order
  dplyr::arrange(code)
```

3. Loading and Cleaning Suicide Rate Data by Municipality

```{r}
# load suicide rate data from Excel file
# the file contains data on the number of suicide casualties per 100,000 people by municipality for years 2021, 2022, and 2023
suicide_rate <- read_excel(here::here("variables", "target variable", "suicide_rate_per_100000_people_by_municipality.xlsx"))

# preprocess suicide rate dataset
suicide_rate <-  suicide_rate %>%
  # translate column names to English
  dplyr::rename(
     municipality = "시군구별",
     gender = "성별"
  ) %>% 
  # keep only rows with overall suicide rate (excluding gender-specific data)
  dplyr::filter(gender == "계") %>%
  # remove rows where 2022 suicide rate is missing ("-")
  dplyr::filter(`2022` != "-") %>% 
  # retain only relevant columns
  dplyr::select("municipality", "2022")

# manually reconcile municipality name discrepancies
suicide_rate_clean <- suicide_rate %>%
  dplyr::mutate(municipality = case_when(
    # account for province or city names that have changed since 2022
    row_number() == 134 ~ "강원도", # province name in 2022
    row_number() == 187 ~ "전라북도", # province name in 2022
    row_number() == 257 ~ "창원시", # city name in 2022
    TRUE ~ municipality
  )) %>%
  # identify administrative unit types (Province, Special City, City, District, County)
  mutate(
    is_province = str_detect(municipality, "도$"), # provinces (도)
    is_special_city = str_detect(municipality, "(특별시|광역시|특별자치시)$"), # special / metropolitan cities (특별시 / 광역시)
    is_city = !is_special_city & str_detect(municipality, "시$"), # ordinary cities (시)
    is_district = str_detect(municipality, "구$"), # districts within cities (구)
    is_county = str_detect(municipality, "군$") # counties within provinces (군)
  ) %>% 
  # assign province, special city, city, district, and county based on classification
  mutate(
    province = ifelse(is_province, municipality, NA),
    special_city = ifelse(is_special_city, municipality, NA),
    city = ifelse(is_city, str_trim(municipality), NA),
    district = ifelse(is_district, str_trim(municipality), NA),
    county = ifelse(is_county, str_trim(municipality), NA)) %>% 
  # fill province names downward
  fill(province, .direction = "down") %>% 
  # fill special city names downward and filter for correct results
  fill(special_city, .direction = "down") %>% 
  mutate(special_city = ifelse(row_number() >= 85, NA, special_city)) %>% 
  # fill city names downward and filter for correct results
  fill(city, .direction = "down") %>% 
  mutate(city = ifelse(is_province | is_county, NA, city)) %>% 
  # concatenate province, special city, city, district, and countries according to the below logic
  dplyr::mutate(municipality_clean = case_when(
    # special / metropolitan cities with districts
    is.na(province) & !is.na(special_city) & is.na(city) & !is.na(district) & is.na(county) ~ paste(special_city, district),
    # special / metropolitan cities with counties
    is.na(province) & !is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(special_city, county),
    # Sejong Special Self-Governing City (unique case)
    is.na(province) & !is.na(special_city) & !is.na(city) & is.na(district) & is.na(county) ~ "세종특별자치시",
    # province-level ordinary cities with districts
    !is.na(province) & is.na(special_city) & !is.na(city) & !is.na(district) & is.na(county) ~ paste(province, city, district),
    # province-level ordinary cities without districts
    !is.na(province) & is.na(special_city) & !is.na(city) & is.na(district) & is.na(county) ~ paste(province, city),
    # province-level counties
    !is.na(province) & is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(province, county),
    TRUE ~ NA
  )
  )%>% 
  # filter out NA values in municipality_clean
  dplyr::filter(!is.na(municipality_clean)) %>% 
  # rename column '2022' to 'suicide_rate'
  dplyr::rename(suicide_rate = `2022`) %>% 
  # retain only final relevant columns
  dplyr::select(municipality_clean, suicide_rate) %>%
  # convert suicide rate to numeric data type
  dplyr::mutate(suicide_rate = as.numeric(suicide_rate))
```

3.1. Merging Suicide Rate Data with Municipality Shapefile

```{r}
# join municipality shapefile with suicide rate data
suicide_rate_municipality <- sk_municipalities_clean %>% 
  # we perform a left join to retain only rows that align with shapefile spatial level
  dplyr::left_join(., suicide_rate_clean, by=c("name" = "municipality_clean")) %>% 
  # retain only relevant columns
  dplyr::select(code, name, suicide_rate)
```

3.2. Exploratory Mapping of Suicide Rates Across South Korean Municipalities

```{r}
# fix invalid geometries in the shapefile
suicide_rate_municipality <- suicide_rate_municipality %>% 
  st_make_valid() # fixes self-intersections and other issues

# check for remaining invalid geometries
sum(!st_is_valid(suicide_rate_municipality)) # should return 0 if all are valid
```

```{r}
# set tmap to interactive mode
tmap_mode("plot")

# generate the suicide rate thematic map
tm_shape(suicide_rate_municipality) +
  tm_polygons("suicide_rate",
              title = "Suicides per 100,000 People",
              palette = "Reds",
              border.col= "black",
              border.alpha= 0.1,
              style = "quantile") +
  tm_layout(main.title = "Suicide Rates Across South Korea (2022)",
            main.title.position = "center",
            main.title.size = 1.2)
```

5. Loading Predictor Variables

5.1. Single Person Household Ratio

```{r}
# load single-person household ratio data
# reads data from excel file containing the percentage of single-person households by municipality in 2022
single_person_household <- read_excel(here::here("variables", "predictor variable", "single_person_household_ratio_by_municipality_2022.xlsx"), col_names=TRUE) %>% 
  # select only relevant columns
  dplyr::select("행정구역별", "1인가구비율<br>(A÷B×100) (%)") %>% 
  # translate columns to English
  dplyr::rename(
     municipality = "행정구역별",
     single_person_household_ratio = "1인가구비율<br>(A÷B×100) (%)"
  )

# clean and standardise municipality names
single_person_household_clean <- single_person_household %>% 
  # account for province or city names that have changed since 2022
  dplyr::mutate(municipality = case_when(
    row_number() == 116 ~ "강원도", # province name in 2022
    row_number() == 163 ~ "전라북도", # province name in 2022
    row_number() == 244 ~ "제주도", # province name in 2022
    TRUE ~ municipality)) %>% 
  # identify administrative unit types (Province, Special City, City, District, County)
  mutate(
    is_province = str_detect(municipality, "도$"), # provinces (도)
    is_special_city = str_detect(municipality, "(특별시|광역시|특별자치시)$"), # special cities / metropolitan cities (특별시 / 광역시)
    is_city = !is_special_city & str_detect(municipality, "시$"), # ordinary cities (시)
    is_district = str_detect(municipality, "구$"), # districts within cities (구)
    is_county = str_detect(municipality, "군$") # counties within provinces (군)
  ) %>% 
  # assign province, special city, city, district, and county based on classification
  mutate(
    province = ifelse(is_province, municipality, NA),
    special_city = ifelse(is_special_city, municipality, NA),
    city = ifelse(is_city, str_trim(municipality), NA),
    district = ifelse(is_district, str_trim(municipality), NA),
    county = ifelse(is_county, str_trim(municipality), NA)) %>% 
  # fill province names downward
  fill(province, .direction = "down") %>% 
  # fill special city names downward and filter for correct results
  fill(special_city, .direction = "down") %>% 
  mutate(special_city = ifelse(row_number() >= 85, NA, special_city)) %>% 
  # fill city names downward and filter for correct results
  fill(city, .direction = "down") %>% 
  mutate(city = ifelse(is_province | is_county, NA, city)) %>% 
  # concatenate province, special city, city, district, and countries according to the below logic
  dplyr::mutate(municipality_clean = case_when(
    # special / metropolitan cities with districts
    is.na(province) & !is.na(special_city) & is.na(city) & !is.na(district) & is.na(county) ~ paste(special_city, district),
    # special / metropolitan cities with counties
    is.na(province) & !is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(special_city, county),
    # Sejong Special Self-Governing City (unique case)
    is.na(province) & special_city == "세종특별자치시" & is.na(city) & is.na(district) & is.na(county) ~ "세종특별자치시",
    # province-level ordinary cities (ordinary city-level districts were not surveyed here, so there is no distinction between the two)
    !is.na(province) & is.na(special_city) & !is.na(city) & is.na(district) & is.na(county) ~ paste(province, city),
    # province-level counties
    !is.na(province) & is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(province, county),
    TRUE ~ NA
  ))%>%
  # filter out NA values in municipality_clean
  dplyr::filter(!is.na(municipality_clean)) %>%
  # retain only final relevant columns
  dplyr::select(municipality_clean, single_person_household_ratio) %>% 
  # convert single person household ratio to numeric data type
  dplyr::mutate(single_person_household_ratio = as.numeric(single_person_household_ratio))
```

5.2. Stress Awareness Rate

```{r}
# load stress awareness rate data
# reads the data from excel file containing stress awareness rates by municipality in 2022
stress_awareness_rate <- read_excel(here::here("variables", "predictor variable", "stress_awareness_rate_by_municipality_2022_2024.xlsx"), col_names=TRUE) %>% 
  # select only relevant columns
  dplyr::select("행정구역별", "2022") %>% 
  # translate columns to English
  dplyr::rename(
     municipality = "행정구역별",
     stress_awareness_rate = "2022"
  )

# clean and standardise municipality names
stress_awareness_rate_clean <- stress_awareness_rate %>% 
  # manually reconcile for municipality names that are inconsistent or changed since 2022
  dplyr::mutate(municipality = case_when(
    row_number() == 115 ~ "강원도", # province name in 2022
    row_number() == 137 ~ "청주시", # city name in 2022
    row_number() == 162 ~ "전라북도", # province name in 2022
    row_number() == 225 ~ "창원시", # city name in 2022
    row_number() == 243 ~ "제주도", # province name in 2022
    TRUE ~ municipality)) %>% 
    # while Jeju province consists of 2 administrative districts (Seogwipo-si and Jeju-si), it has been surveyed as a single district in the dataset
    # this step breaks Jeju down into 2 administrative units and assigns the value for Jeju province to each
    # this is to be consistent with our shapefile and suicide rate data
  bind_rows(
    stress_awareness_rate %>%
    filter(str_starts(municipality, "제주")) %>%
    slice(rep(1:n(), each = 2))) %>% # duplicate Jeju row
  dplyr::mutate(municipality = case_when(
    row_number() == 244 ~ "제주시", # Jeju city
    row_number() == 245 ~ "서귀포시", # Seogwipo city
    TRUE ~ municipality)) %>% 
  # identify Administrative Unit Types (Province, Special City, City, District, County)
  mutate(
    is_province = str_detect(municipality, "도$"), # provinces (도)
    is_special_city = str_detect(municipality, "(특별시|광역시|특별자치시)$"), # special / metropolitan cities (특별시 / 광역시)
    is_city = !is_special_city & str_detect(municipality, "시$"), # ordinary cities (시)
    is_district = str_detect(municipality, "구$"), # districts within cities (구)
    is_county = str_detect(municipality, "군$") # counties within provinces (군)
  ) %>% 
  # assign province, special city, city, district, and county based on classification
  mutate(
    province = ifelse(is_province, municipality, NA),
    special_city = ifelse(is_special_city, municipality, NA),
    city = ifelse(is_city, str_trim(municipality), NA),
    district = ifelse(is_district, str_trim(municipality), NA),
    county = ifelse(is_county, str_trim(municipality), NA)) %>% 
  # fill province names downward
  fill(province, .direction = "down") %>% 
  # fill special city names downward and filter for correct results
  fill(special_city, .direction = "down") %>% 
  mutate(special_city = ifelse(row_number() >= 83, NA, special_city)) %>% 
  # fill city names downward and filter for correct results
  fill(city, .direction = "down") %>% 
  mutate(city = ifelse(is_province | is_county, NA, city)) %>% 
  # concatenate province, special city, city, district, and countries according to the below logic
  dplyr::mutate(municipality_clean = case_when(
    # special / metropolitan cities with districts
    is.na(province) & !is.na(special_city) & is.na(city) & !is.na(district) & is.na(county) ~ paste(special_city, district),
    # special / metropolitan cities with counties
    is.na(province) & !is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(special_city, county),
    # Sejong Special Self-Governing City (unique case)    
    is.na(province) & special_city == "세종특별자치시" & is.na(city) & is.na(district) & is.na(county) ~ "세종특별자치시",
    # province-level ordinary cities (ordinary city-level districts were not surveyed here, so there is no distinction between the two)
    !is.na(province) & is.na(special_city) & !is.na(city) & is.na(district) & is.na(county) ~ paste(province, city),
    # province-level counties    
    !is.na(province) & is.na(special_city) & is.na(city) & is.na(district) & !is.na(county) ~ paste(province, county),
    TRUE ~ NA
  ))%>%
  # filter out NA values in municipality_clean
  dplyr::filter(!is.na(municipality_clean)) %>%
  # retain only final relevant columns
  dplyr::select(municipality_clean, stress_awareness_rate) %>% 
  # convert single person household ratio to numeric data type
  dplyr::mutate(stress_awareness_rate = as.numeric(stress_awareness_rate))
```

5.3. Unemployment Rate

```{r}
# load unemployment rate data
# reads the data from excel file containing unemployment rates by municipality in 2022
unemployment_rate <- read_excel(here::here("variables", "predictor variable", "unemployment_rate_by_municipality_2022.xlsx"), col_names=TRUE) %>% 
  # select only relevant columns
  dplyr::select("행정구역별", "2022.2/2") %>% 
  # translate columns to English
  dplyr::rename(
     municipality = "행정구역별",
     unemployment_rate = "2022.2/2"
  )

# clean and standardise municipality names
unemployment_rate_clean <- unemployment_rate %>%
  # fix inconsistencies in city/province naming conventions
  dplyr::mutate(municipality = str_replace(municipality, "^서울", "서울특별시")) %>% # special city
  dplyr::mutate(municipality = str_replace(municipality, "^(부산|대구|인천|광주|대전|울산)", "\\1광역시")) %>%  # metropolitan cities
  mutate(municipality = case_when(
    # assign "경기도" to its municipalities
    str_detect(municipality, "^(수원시|성남시|의정부시|안양시|부천시|광명시|평택시|동두천시|안산시|고양시|과천시|구리시|남양주시|오산시|시흥시|군포시|의왕시|하남시|용인시|파주시|이천시|안성시|김포시|화성시|양주시|포천시|여주시|연천군|가평군|양평군)$") ~ 
      str_c("경기도 ", municipality),
    # assign "강원도" to its municipalities
    str_detect(municipality, "^(춘천시|원주시|강릉시|동해시|태백시|속초시|삼척시|홍천군|횡성군|영월군|평창군|정선군|철원군|화천군|양구군|인제군|고성군|양양군)$") ~ 
      str_c("강원도 ", municipality),
    # assign "충청북도" to its municipalities
    str_detect(municipality, "^(청주시|충주시|제천시|보은군|옥천군|영동군|진천군|괴산군|음성군|단양군|증평군)$") ~ 
      str_c("충청북도 ", municipality),
    # assign "충청남도" to its municipalities
    str_detect(municipality, "^(천안시|공주시|보령시|아산시|서산시|논산시|계룡시|당진시|금산군|부여군|서천군|청양군|홍성군|예산군|태안군)$") ~ 
      str_c("충청남도 ", municipality),
    # assign "전라북도" to its municipalities
    str_detect(municipality, "^(전주시|군산시|익산시|정읍시|남원시|김제시|완주군|진안군|무주군|장수군|임실군|순창군|고창군|부안군)$") ~ 
      str_c("전라북도 ", municipality),
    # assign "전라남도" to its municipalities
    str_detect(municipality, "^(목포시|여수시|순천시|나주시|광양시|담양군|곡성군|구례군|고흥군|보성군|화순군|장흥군|강진군|해남군|영암군|무안군|함평군|영광군|장성군|완도군|진도군|신안군)$") ~ 
      str_c("전라남도 ", municipality),
    # assign "경상북도" to its municipalities
    str_detect(municipality, "^(포항시|경주시|김천시|안동시|구미시|영주시|영천시|상주시|문경시|경산시|의성군|청송군|영양군|영덕군|청도군|고령군|성주군|칠곡군|예천군|봉화군|울진군|울릉군)$") ~ 
      str_c("경상북도 ", municipality),
    # assign "경상남도" to its municipalities
    str_detect(municipality, "^(진주시|통영시|사천시|김해시|밀양시|거제시|양산시|창원시|의령군|함안군|창녕군|고성군|남해군|하동군|산청군|함양군|거창군|합천군)$") ~ 
      str_c("경상남도 ", municipality),
    # assign "제주도" to its municipalities
    str_detect(municipality, "^(제주시|서귀포시)$") ~ 
      str_c("제주도 ", municipality),
    TRUE ~ municipality # there shouldn't be any exceptions
  )) %>% 
  # manually handle name discrepancies not covered above & errors introduced by the above due to duplicate municipality names in different provinces
    dplyr::mutate(municipality = 
                    ifelse(str_detect(municipality, "대구광역시 군위군"),
      "경상북도 군위군", municipality)) %>% 
    dplyr::mutate(municipality = 
                    ifelse(row_number() == 220 & str_detect(municipality, "강원도 고성군"), "경상남도 고성군", municipality)) %>% 
    dplyr::mutate(municipality = 
                    ifelse(row_number() == 100 & str_detect(municipality, "광주광역시시"), "경기도 광주시", municipality)) %>% 
  dplyr::rename(municipality_clean = municipality) %>% 
  dplyr::mutate(unemployment_rate = as.numeric(unemployment_rate))

# handle missing row for Sejong Special Self-Governing City
# since Sejong's unemployment rate is missing, we impute it using the the average unemployment rate of neighbouring provinces (충청북도, 충청남도, 대전)
chungcheong_avg_unemployment <- unemployment_rate_clean %>%
  filter(str_detect(municipality_clean, "충청북도|충청남도|대전광역시")) %>%
  summarise(mean_unemployment = mean(unemployment_rate, na.rm = TRUE)) %>%
  pull(mean_unemployment)

# if Sejong is missing, impute it with the calculated average
if(!any(unemployment_rate_clean$municipality_clean == "세종특별자치시")) {
sejong_unemployment <- tibble(
  municipality_clean = "세종특별자치시",
  unemployment_rate = round(chungcheong_avg_unemployment, 1)
)
# add Sejong to the dataset
unemployment_rate_clean <- unemployment_rate_clean %>%
  bind_rows(sejong_unemployment)
}
```

5.4. Unmet Medical Needs

```{r}
# load unmet medical needs data
# reads the data from excel file containing unmet medical needs by municipality in 2022
unmet_medical_needs <- read_excel(here::here("variables", "predictor variable", "unmet_medical_needs_rate_by_municipality_2022_2024.xlsx"), col_names=TRUE) %>% 
  # select only relevant columns
  dplyr::select("시군구별(1)", "시군구별(2)", "2022") %>% 
  # translate columns to English
  dplyr::rename(
     municipality_level_1 = "시군구별(1)", # higher administrative level (province / special/ metropolitan city)
     municipality_level_2 = "시군구별(2)", # lower administrative level (city / county / district)
     unmet_medical_needs_rate = "2022"
  )

# clean and standardise municipality names
unmet_medical_needs_clean <- unmet_medical_needs %>% 
  # remove rows where 'municipality_level_2' is '소계' (subtotal)
  dplyr::filter(municipality_level_2 != "소계") %>% 
  # standardise province names to be consisent with their names in 2022
  dplyr::mutate(municipality_level_1 = str_replace(municipality_level_1, "^전북특별자치도", "전라북도"),
         municipality_level_1 = str_replace(municipality_level_1, "^강원특별자치도", "강원도"),
         municipality_level_1 = str_replace(municipality_level_1, "^제주특별자치도", "제주도")
         ) %>% 
  # combine municipality_level_1 with municipality_level_2 for to get full municipality names
  dplyr::mutate(municipality_clean = paste(municipality_level_1, municipality_level_2)) %>% 
  # manually handle the error introduced by above for the special case of Sejong Special Self-Governing City
  dplyr::mutate(municipality_clean = 
                    ifelse(str_detect(municipality_clean, "세종특별자치시 세종시"),
      "세종특별자치시", municipality_clean)) %>% 
  # retain only relevant columns
  dplyr::select(municipality_clean, unmet_medical_needs_rate) %>%
  # conveert unmet medical needs rate colun to numeric type
  dplyr::mutate(unmet_medical_needs_rate = as.numeric(unmet_medical_needs_rate))
```

5.5. Municipality Population (for expected values & suicide counts)

```{r}
# load municipality population data
# reads resident registration population data in 2022 by municipality from excel file
municipality_population_2022 <- read_excel(here::here("variables", "predictor variable", "resident_registration_population_by_administrative_district_2022.xlsx"), col_names=TRUE) %>% 
  # select only relevant columns
  dplyr::select("행정기관", "총인구수", "남자 인구수", "여자 인구수") %>% 
  # translate columns to English
  dplyr::rename(
     municipality = "행정기관",
     total_population = "총인구수",
     male_population = "남자 인구수",
     female_population = "여자 인구수"
  ) %>% 
  # standardise municipality names
  dplyr::mutate(municipality = str_replace(municipality, "^제주특별자치도", "제주도"),
                # convert population values from strings with commas to numeric
                total_population = as.numeric(str_replace_all(total_population, ",", "")),
                male_population = as.numeric(str_replace_all(male_population, ",", "")),
                female_population = as.numeric(str_replace_all(female_population, ",", "")),) %>% 
  # filter only for rows where 1. the municipality is Sejong or 2. the municipality name contains exactly one space, ensuring correct administrative level
  dplyr::filter(municipality == "세종특별자치시" | str_count(municipality, "\\s") == 1) %>% 
  # remove duplicate entries for Sejong
  dplyr::distinct() %>% 
  # rename municipality column to municipality_clean for consistency across datasets
  dplyr::rename(municipality_clean = municipality)
```

6. Join Predictor Variables into suicide_rate_municipality dataframe

```{r}
# read in a mapping file that converts Korean municipality names to English
kr_to_en_mapping <- read_excel(here::here("mapping", "korean_to_english_mapping.xlsx"))

# merge all predictor variables with the suicide rate data
model_df <- suicide_rate_municipality %>% 
  # join single-person household ratio
  dplyr::left_join(., single_person_household_clean, by=c("name" = "municipality_clean")) %>% 
  # join stress awareness rate
  dplyr::left_join(., stress_awareness_rate_clean, by=c("name" = "municipality_clean")) %>% 
  # join unemployment rate
  dplyr::left_join(., unemployment_rate_clean, by=c("name" = "municipality_clean")) %>% 
  # join unmet medical needs rate
  dplyr::left_join(., unmet_medical_needs_clean, by=c("name" = "municipality_clean")) %>% 
  # join municipality population data (for expected values & suicide counts)
  dplyr::left_join(., municipality_population_2022, by=c("name" = "municipality_clean")) %>% 
  # join Korean-to-English name mapping
  dplyr::left_join(., kr_to_en_mapping, by=c("name" = "municipality_kr")) %>% 
  # compute additional features
  # calculate municipality area (in km²)
  dplyr::mutate(., area = as.numeric(set_units(st_area(geometry), "km^2"))) %>% 
  # calculate population density (people per km²)
  dplyr::mutate(population_density_km2 = round((total_population / area),1)) %>%
  # calculate estimated suicide count
  # we use the suicide rate (per 100,000 people) to estimate actual suicide counts from 2022 population
  # round to the nearest integer for modelling purposes
  dplyr::mutate(suicide_count = as.integer(round(total_population * suicide_rate / 100000, 0))) %>% 
  # select rename relevant columns and keep only necessary variables for modelling
  dplyr::select(code, municipality_en, suicide_count, single_person_household_ratio, stress_awareness_rate, unemployment_rate, unmet_medical_needs_rate, population_density_km2, total_population) %>% 
  # rename 'municipality_en' to 'name'
  dplyr::rename(name = municipality_en)
```

7. Data Preparation for ICAR Model

```{r}
# # quick diagnosis with variance-to-mean ratio
# var(model_df$suicide_count) / mean(model_df$suicide_count)
# 
# var(model_df$suicide_count)
# 
# # Create histogram for suicide counts
# ggplot(model_df, aes(x = suicide_count)) +
#   geom_histogram(binwidth = 5, fill = "darkblue", color = "white", alpha = 0.7) +
#   geom_density(aes(y = ..count.. * 5), color = "red", size = 1) +
#   labs(title = "Reported Number of Suicide in Korean Municipalities",
#        x = "Suicide Counts",
#        y = "Frequency") +
#   theme_minimal() +
#   theme(plot.title = element_text(hjust = 0.5, face = "bold"),
#         axis.title = element_text(size = 12),
#         axis.text = element_text(size = 10))
# 
# # see lowest count
# min(model_df$suicide_count)
# # see highest count
# max(model_df$suicide_count)
# 
# # since we are considering using the Negative Binomial Poisson Regression, let us estimate the over-dispersion parameter using the glm.nb() function
# 
# # fit negative binomial regression null model
# nb_model <- glm.nb(suicide_count ~ 1, data=model_df)
# 
# # extract theta
# theta <- nb_model$theta
# 
# theta
# 
# # the estimated over-dispersion parameter is 1.28132
# # the theta (dispersion) parameter in a negatival binomial model controls the degree of overdispersion relative to a Poisson distribution
# # a higher theta value suggests less overdisperison, while a lower theta value suggests more overdispersion
# # my value is 1.28132, meaning the suicide_count data is overdispersed but not extremely so
# # in a Poisson regression, the variance equals the mean (Var(Y) = E(Y))
# # in a negative binomial model, variance is greater than the mean: Var(Y) = mu + mu^2 / theta
# # NB model can be used to characterise count data where the majority of data points are clustered toward lower values of a variable
# # When choosing between a negative binomial model and a Poisson model, use a negative binomial model if your count data exhibits overdispersion (variance greater than the mean), while a Poisson model is suitable when the variance is roughly equal to the mean in your count data; essentially, the negative binomial model is a more flexible option that can handle situations where the Poisson model's assumptions are not met

# Three types of Poisson models
# 
# - Standard Poisson Regression
# - Negative Binomial Poisson Regression
# - Zero-Inflated Poisson Regression
# 
# The implementation of these models are highly dependent on how the frequency distribution of the count response variable are displayed
# 
# If it resembles a normal curve - then use the standard version
# Otherwise, use the Negative Binomial Poisson regression if there is any evidence of over-dispersion
# When there is an inflation of zero counts in the dataset, you will have to use the Zero-Inflated Poisson model
```

7.1. RStan Configuration

```{r}
# enable parallel processing in RStudio for Stan
# parallel::detectCores() automatically detects the number of CPU cores available on my local machine
options(mc.cores = parallel::detectCores())
# rtan_options(auto_write = TRUE) saves compiled models to avoid redundant compilation
rstan_options(auto_write = TRUE)
```


7.2. Calculate Expected Numbers

```{r}
# in order to estimate the risk of casualties due to suicide across Korean municipalities, we will need to first obtain a column that contains estimated expected number of casualties. This is derived from the total_population column.
# n.strata = 1 means that no stratification is being applied - the entire dataset is treated as a single stratum
# this will be used as an offset in our spatial model
model_df$expected_num <- round(expected(population = model_df$total_population, cases = model_df$suicide_count, n.strata = 1), 0)
```

7.3. Converting the Spatial Adjacency Matrix to Nodes & Edges

```{r}
# convert model_df to a spatial object
# poly2nb() from the spdep package works with sp objects, not sf objects
model_df_sp <- as(model_df, "Spatial")

# create standard adjacency matrix using Queen contiguity
# Queen's contiguity considers any shared boundary or shared vertex as a neighbour
# the 'snap = 200' argument ensures that near-touching polygons within 200m are considered contiguous
adj_list <- poly2nb(model_df_sp, queen = TRUE, snap = 200)

# inspect adj_list
# the list has 6 subgraphs and 4 isoalted regions (59, 177, 184, 190) with no links
adj_list

# we need to convert the list-based adjacency strucuture into an igraph object to analyse connected components
graph_adj <- graph_from_adj_list(adj_list, mode = "all")

# identify subgraph components
subgraph_labels <- components(graph_adj)$membership
model_df$subgraph <- as.factor(subgraph_labels)

# find the largest subgraph (mainland Korea)
largest_subgraph <- which.max(table(subgraph_labels))

# identify all smaller disconnected subgraphs
# this returns a list of subgraph IDs
disconnected_subgraphs <- unique(subgraph_labels[subgraph_labels != largest_subgraph])

# inspect disconnected subgraphs
disconnected_subgraphs  # Should return a list of subgraph IDs

# inspect the current state of subgraph connectivity
ggplot() +
  geom_sf(data = model_df, aes(fill = as.factor(subgraph_labels)), color = "black") +
  scale_fill_viridis_d(option = "turbo", name = "Subgraph")  +
  ggtitle("Current Subgraph Connectivity in South Korea") +
  theme_minimal()

# convert centroids to an sf object
centroids <- st_centroid(model_df$geometry)
centroids_sf <- st_as_sf(data.frame(id = 1:length(centroids), geometry = centroids))

# iterate through each disconnected subgraph
for (subgraph in disconnected_subgraphs) {
  # find polygons in the current subgraph
  subgraph_polygons <- which(subgraph_labels == subgraph)
  
  # find polygons in the largest subgraph (mainland)
  mainland_polygons <- which(subgraph_labels == largest_subgraph)
  
  # find nearest polygon in the mainland for each polygon in the subgraph
  closest_mainland <- st_nearest_feature(centroids_sf[subgraph_polygons, ], centroids_sf[mainland_polygons, ])
  
  # convert closest_mainland to integer indices
  closest_mainland <- as.integer(closest_mainland)
  
  # update adjacency list to connect subgraph polygons to mainland
  for (i in seq_along(subgraph_polygons)) {
    island <- subgraph_polygons[i]
    mainland <- closest_mainland[i]
    
    # ensure bidirectional connection
    adj_list[[island]] <- unique(c(adj_list[[island]], mainland))
    adj_list[[mainland]] <- unique(c(adj_list[[mainland]], island))
  }
}

# identify which nodes have invalid `0` entries (0, 58) for example
invalid_nodes <- which(sapply(adj_list, function(x) any(x == 0)))

# rint the invalid nodes
print(invalid_nodes)  # Should show 59, 177, 184, 190, etc.

# loop through adj_list and remove zeroes
adj_list <- lapply(adj_list, function(x) x[x != 0])

# verify that 0s are gone
nodes_to_check <- c(59, 177, 184, 190)
print(adj_list[nodes_to_check])

# recompute the graph after linking all subgraphs
graph_adj <- graph_from_adj_list(adj_list, mode = "all")
subgraph_labels <- components(graph_adj)$membership
model_df$subgraph <- as.factor(subgraph_labels)

# check if any disconnected subgraphs remain
remaining_disconnected <- unique(subgraph_labels[subgraph_labels != largest_subgraph])

if (length(remaining_disconnected) == 0) {
  message("All regions are now fully connected.")
} else {
  message("Some subgraphs are still disconnected: ", paste(remaining_disconnected, collapse = ", "))
}

# visualise the updated subgraph connectivity
ggplot() +
  geom_sf(data = model_df, aes(fill = as.factor(subgraph_labels)), color = "black") +
  scale_fill_viridis_d(option = "turbo", name = "Subgraph") +
  ggtitle("Updated Subgraph Connectivity in South Korea") +
  theme_minimal()

View(graph_adj)

# convert the updated graph to an adjacency matrix
adjacency_matrix <- as_adjacency_matrix(graph_adj, sparse = TRUE)

adjacency_matrix <- Matrix::Matrix(as(adjacency_matrix, "sparseMatrix") > 0, sparse = TRUE)

adjacency_matrix
```

```{r}
# extract the components for the ICAR model using the prep_icar_data function
extract_components <- prep_icar_data(adjacency_matrix)

# the extract_components object contains the following key elements:
# group_size is the total number of areal units observed in the shapefile
# node1 are indexes of the regions of interest - the focal areas in the adjacency matrix
# node2 shows corresponding neighbouring regions that are connected to the regions in node1. This defines spatial relationships
# n_edges represents the number of edges in the network, defining the spatial connections. It transforms the adjacency matrix (based on a Queen contiguity matrix) into a network structure showing which areas are directly connected to others

# extract key elements
n <- as.numeric(extract_components$group_size)
nod1 <- extract_components$node1
nod2 <- extract_components$node2
n_edges <- as.numeric(extract_components$n_ed)
```

7.4. Create the Dataset to be compiled in Stan

```{r}
# the outcome suicide_count, independent variables single_person_household_ratio, stress_awareness_rate, unemployment_rate, unmet_medical_needs_rate, and the offset variable expected_num need to be extracted into separate vectors
y <- model_df$suicide_count # outcome variable (suicide casualties)
# extract multiple independent variables into a matrix
X <- model_df %>%
  st_drop_geometry() %>%
  dplyr::select(single_person_household_ratio, 
                stress_awareness_rate,
                unemployment_rate, 
                unmet_medical_needs_rate) %>%
  as.matrix()
e <- model_df$expected_num
```

```{r}
stan_spatial_dataset <- list(
  N = nrow(model_df) , # number of spatial units
  N_edges = n_edges, # number of edges in spatial adjacency structure
  node1 = nod1, # first node in adjacency structure
  node2 = nod2, # second node in adjacency structure
  Y = y, # outcome variable (suicide casualties)
  X = X, # matrix of independent variables (3 predictors)
  K = ncol(X), # number of independent variables (3)
  Off_set = e # offset variable (expected_num)
)

# inspect
stan_spatial_dataset
```

7.5. Compiling Stan code for Spatial ICAR Risk Modelling

7.5.1. Printing of the Global Results

```{r}
# start the clock
ptm <- proc.time()

# fit icar_poisson_stan model
icar_poisson_fit = stan("icar_poisson_model.stan",
                        data = stan_spatial_dataset,
                        iter = 12000,
                        warmup = 6000,
                        control = list(adapt_delta = 0.99, max_treedepth = 12),
                        chain = 6,
                        verbose = FALSE)

# stop the clock
proc.time() - ptm
```

```{r}
# we can see our estimated results for alpha, beta, and sigma
options(scipen = 999)
summary(icar_poisson_fit, pars=c("alpha", "beta", "sigma"), probs=c(0.025, 0.975))$summary

View(icar_poisson_fit)
```

```{r}
exp(-0.038103413)
```


```{r}
cor_matrix <- cor(model_df[, c("single_person_household_ratio", 
                               "stress_awareness_rate", 
                               "unemployment_rate", 
                               "unmet_medical_needs_rate")])
print(cor_matrix)
```

```{r}
# print full table to avoid some rows from being omitted.
options(max.print = 100000)
# print the results
print(icar_poisson_fit, pars=c("alpha", "beta", "rr_alpha", "rr_beta", "rr_mu", "sigma"), probs=c(0.025, 0.975))
```

```{r}
# diagnostic check on the rHats - put everything into a data frame
diagnostic.checks <- as.data.frame(summary(icar_poisson_fit, pars=c("alpha", "beta", "rr_alpha", "rr_beta", "rr_mu", "sigma", "phi", "lp__"), probs=c(0.025, 0.5, 0.975))$summary)
# create binary variable
diagnostic.checks$valid <- ifelse(diagnostic.checks$Rhat < 1.05, 1, 0)
# tabulate it
table(diagnostic.checks$valid)
```

